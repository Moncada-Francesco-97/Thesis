{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir ='/Users/francesco/Desktop/Thesis/Data/'\n",
    "\n",
    "# Read the dataframes\n",
    "df_bed = xr.open_dataset(datadir + 'BedMachineAntarctica-v3.nc')\n",
    "df_melt = xr.open_dataset(datadir + 'bmelt_bmachine_grid_v1.nc')\n",
    "\n",
    "#Adding the names of the glaciers, in order to select later the interesting ones\n",
    "df_names = pd.read_csv(datadir + 'Merged_Integrated_melt_rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the variables\n",
    "\n",
    "thickness = df_bed.thickness #dim -> (x,y)\n",
    "melt = df_melt.melt #dim -> (t,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_bed.x\n",
    "y = df_bed.y\n",
    "time = df_melt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n#Creatinng the mesh grid\\ncoord = x.values\\nX, Y = np.meshgrid(coord, coord)\\n\\n\\nplt.figure(figsize=(10,10))\\nplt.pcolormesh(X, Y, bed, cmap='gist_earth')\\nplt.colorbar()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the bed with the meshgrid\n",
    "\n",
    "''' \n",
    "#Creatinng the mesh grid\n",
    "coord = x.values\n",
    "X, Y = np.meshgrid(coord, coord)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.pcolormesh(X, Y, bed, cmap='gist_earth')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I want to select the areas of the region of interest, and there I want to calculate the basal melt\n",
    "#just for the thickest part of the glacier, i.e. the part of the glacier where the thickness is above the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from shapely.geometry import shape\n",
    "import csv\n",
    "#from mapxy import mapxy\n",
    "import pyproj\n",
    "#from ps_latlon_conversion import xyscale_south\n",
    "import pyproj\n",
    "#import ogr\n",
    "from osgeo import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "import rasterio.mask\n",
    "from fiona import Feature, Geometry\n",
    "from shapely.geometry import mapping, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/francesco/Desktop/Data/GEOTIFFs/melt_1992_warp_ps.tif\n",
      "{'id': 'int:10', 'name': 'str:30', 'regions': 'str:11', 'type': 'str:2', 'is_index': 'int:10', 'ice_shelf_': 'str:50', 'measures_n': 'str:50', 'latitude': 'float:24.15', 'longitude': 'float:24.15', 'thickness_': 'float:24.15', 'thicknes_1': 'float:24.15', 'smb_mean_9': 'float:24.15', 'smb_mean_1': 'float:24.15', 'ss_gl_flux': 'float:24.15', 'ss_gl_fl_1': 'float:24.15', 'ss_calving': 'float:24.15', 'ss_calvi_1': 'float:24.15', 'model_gl_f': 'float:24.15', 'instant_co': 'float:24.15', 'mass_loss_': 'float:24.15', 'mass_los_1': 'float:24.15', 'mass_los_2': 'float:24.15', 'mass_los_3': 'float:24.15', 'mass_los_4': 'float:24.15', 'mass_los_5': 'float:24.15', 'mass_los_6': 'float:24.15', 'mass_los_7': 'float:24.15', 'mass_los_8': 'float:24.15', 'mass_los_9': 'float:24.15', 'mass_los10': 'float:24.15', 'mass_los11': 'float:24.15', 'mass_los12': 'float:24.15', 'mass_los13': 'float:24.15', 'mass_los14': 'float:24.15', 'mass_los15': 'float:24.15', 'mass_los16': 'float:24.15', 'mass_los17': 'float:24.15', 'mass_los18': 'float:24.15', 'mass_los19': 'float:24.15', 'mass_los20': 'float:24.15', 'mass_los21': 'float:24.15', 'mass_los22': 'float:24.15', 'mass_los23': 'float:24.15', 'mass_los24': 'float:24.15', 'mass_los25': 'float:24.15', 'mass_los26': 'float:24.15', 'mass_los27': 'float:24.15', 'mass_los28': 'float:24.15', 'mass_los29': 'float:24.15', 'mass_los30': 'float:24.15', 'mass_los31': 'float:24.15', 'mass_los32': 'float:24.15', 'mass_los33': 'float:24.15', 'mass_los34': 'float:24.15', 'mass_los35': 'float:24.15', 'mass_los36': 'float:24.15', 'mass_los37': 'float:24.15', 'mass_los38': 'float:24.15', 'mass_los39': 'float:24.15', 'mass_los40': 'float:24.15', 'mass_los41': 'float:24.15', 'mass_los42': 'float:24.15', 'mass_los43': 'float:24.15', 'mass_los44': 'float:24.15', 'mass_los45': 'float:24.15', 'mass_los46': 'float:24.15', 'mass_los47': 'float:24.15', 'mass_los48': 'float:24.15', 'rel97_mass': 'float:24.15', 'rel97_ma_1': 'float:24.15', 'rel97_ma_2': 'float:24.15', 'rel97_ma_3': 'float:24.15', 'rel97_ma_4': 'float:24.15', 'rel97_ma_5': 'float:24.15', 'rel97_ma_6': 'float:24.15', 'rel97_ma_7': 'float:24.15', 'rel97_ma_8': 'float:24.15', 'rel97_ma_9': 'float:24.15', 'rel97_ma10': 'float:24.15', 'rel97_ma11': 'float:24.15', 'rel97_ma12': 'float:24.15', 'rel97_ma13': 'float:24.15', 'rel97_ma14': 'float:24.15', 'rel97_ma15': 'float:24.15', 'rel97_ma16': 'float:24.15', 'rel97_ma17': 'float:24.15', 'rel97_ma18': 'float:24.15', 'rel97_ma19': 'float:24.15', 'rel97_ma20': 'float:24.15', 'rel97_ma21': 'float:24.15', 'rel97_ma22': 'float:24.15', 'rel97_ma23': 'float:24.15', 'rel97_ma24': 'float:24.15', 'rel97_ma25': 'float:24.15', 'rel97_ma26': 'float:24.15', 'rel97_ma27': 'float:24.15', 'rel97_ma28': 'float:24.15', 'rel97_ma29': 'float:24.15', 'rel97_ma30': 'float:24.15', 'rel97_ma31': 'float:24.15', 'rel97_ma32': 'float:24.15', 'rel97_ma33': 'float:24.15', 'rel97_ma34': 'float:24.15', 'rel97_ma35': 'float:24.15', 'rel97_ma36': 'float:24.15', 'rel97_ma37': 'float:24.15', 'rel97_ma38': 'float:24.15', 'rel97_ma39': 'float:24.15', 'rel97_ma40': 'float:24.15', 'rel97_ma41': 'float:24.15', 'rel97_ma42': 'float:24.15', 'rel97_ma43': 'float:24.15', 'rel97_ma44': 'float:24.15', 'rel97_ma45': 'float:24.15', 'rel97_ma46': 'float:24.15', 'rel_mass_l': 'float:24.15'}\n"
     ]
    }
   ],
   "source": [
    "#get information from the shp file\n",
    "\n",
    "path_to_tif = '/Users/francesco/Desktop/Data/GEOTIFFs/'\n",
    "shapefile_path = '/Users/francesco/Desktop/Thesis/Data/ice_shelf.shp'\n",
    "\n",
    "ids = []\n",
    "Names = []\n",
    "lat_lon_coords = []\n",
    "regions = []\n",
    "boundaries = []\n",
    "areas = []\n",
    "\n",
    "\n",
    "#Here i just uses the first tif file to get the information, so 1992\n",
    "file_tif = path_to_tif + 'melt_' + str(1992) + '_warp_ps.tif'\n",
    "print(file_tif)\n",
    "\n",
    "\n",
    "shapefile=fiona.open(shapefile_path)\n",
    "print(shapefile.schema['properties'])\n",
    "\n",
    "\n",
    "for feature in shapefile:\n",
    "\n",
    "\n",
    "    id = feature['id']\n",
    "    name=feature['properties']['name']\n",
    "    geometry=feature['geometry']\n",
    "    region = feature['properties']['regions']\n",
    "    lat = feature['properties']['latitude']\n",
    "    lon = feature['properties']['longitude']\n",
    "    #thickness = feature['properties']['thickness_']\n",
    "\n",
    "    bounds=shape(geometry).bounds\n",
    "    xmin=bounds[0];ymin=bounds[1];xmax=bounds[2];ymax=bounds[3]\n",
    "\n",
    "    area_temp = np.abs((xmax-xmin)*(ymax-ymin))\n",
    "\n",
    "    #Taking the info\n",
    "    ids.append(id)\n",
    "    Names.append(name)\n",
    "    lat_lon_coords.append([lat,lon])\n",
    "    regions.append(region)\n",
    "    boundaries.append([xmin,xmax,ymin,ymax])\n",
    "    areas.append(area_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nYears = np.arange(1992, 2018, 1)\\nthickness_mean = np.zeros(len(ids))\\nmelt_mean = np.zeros((len(ids), len(time)))\\nprint(np.shape(melt_mean))\\n\\n\\nfor glacier in range(0, len(ids)):\\n    x_min , x_max, y_min, y_max =  boundaries[glacier]\\n    mask = (x > x_min) & (x < x_max) & (y > y_min) & (y < y_max)\\n    print('Glacier number: ', glacier)\\n    \\n    # index both thickness and melt using the mask\\n    thickness_roi = thickness.where(mask, drop=True)\\n    thickness_mean_roi = np.mean(thickness_roi)\\n    thickness_mean[glacier] = thickness_mean_roi\\n\\n    \\n    for t in range(0, len(time)):\\n        melt_roi = melt[t].where(mask, drop=True)\\n        melt_mean_temp = np.nanmean(melt_roi.where(thickness_roi > thickness_mean_roi))\\n        melt_mean[glacier, t] = melt_mean_temp\\n\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This block of code is to calculate the mean thickness and the mean melt for the thickest part of the glacier.\n",
    "#Is commented since the output is already saved in the csv file\n",
    "\n",
    "\n",
    "#The idea is to create a loop that goes through all the glaciers, 18 minuti\n",
    "#and for each glacier it creates a mask, and then it calculates the mean thickness and the mean melt for the thickest part of the glacier\n",
    "\n",
    "''' \n",
    "Years = np.arange(1992, 2018, 1)\n",
    "thickness_mean = np.zeros(len(ids))\n",
    "melt_mean = np.zeros((len(ids), len(time)))\n",
    "print(np.shape(melt_mean))\n",
    "\n",
    "\n",
    "for glacier in range(0, len(ids)):\n",
    "    x_min , x_max, y_min, y_max =  boundaries[glacier]\n",
    "    mask = (x > x_min) & (x < x_max) & (y > y_min) & (y < y_max)\n",
    "    print('Glacier number: ', glacier)\n",
    "    \n",
    "    # index both thickness and melt using the mask\n",
    "    thickness_roi = thickness.where(mask, drop=True)\n",
    "    thickness_mean_roi = np.mean(thickness_roi)\n",
    "    thickness_mean[glacier] = thickness_mean_roi\n",
    "\n",
    "    \n",
    "    for t in range(0, len(time)):\n",
    "        melt_roi = melt[t].where(mask, drop=True)\n",
    "        melt_mean_temp = np.nanmean(melt_roi.where(thickness_roi > thickness_mean_roi))\n",
    "        melt_mean[glacier, t] = melt_mean_temp\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nYears = np.arange(1992, 2018, 1)\\nnp.savetxt('thickness_and_basal_mean.csv', np.column_stack((thickness_mean, melt_mean)), delimiter=',')\\nnp.savetxt('melt_mean_1.csv', melt_mean, delimiter=',', header=','.join(map(str, Years)))\\nnp.savetxt('thickness_mean_1.csv', thickness_mean, delimiter=',', header=','.join(map(str, Names)))\\n\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save as CSV file\n",
    "\n",
    "''' \n",
    "Years = np.arange(1992, 2018, 1)\n",
    "np.savetxt('thickness_and_basal_mean.csv', np.column_stack((thickness_mean, melt_mean)), delimiter=',')\n",
    "np.savetxt('melt_mean_1.csv', melt_mean, delimiter=',', header=','.join(map(str, Years)))\n",
    "np.savetxt('thickness_mean_1.csv', thickness_mean, delimiter=',', header=','.join(map(str, Names)))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv file and extracting the variables\n",
    "data_dir_2 = '/Users/francesco/Desktop/Thesis/Bed_machine/'\n",
    "\n",
    "melt_mean = pd.read_csv(data_dir_2 + 'melt_mean_1.csv')\n",
    "thickness_mean = pd.read_csv(data_dir_2 + 'thickness_mean_1.csv')\n",
    "\n",
    "\n",
    "\n",
    "#Here I import the dataset for the glaciers that I am interested in\n",
    "\n",
    "df_names = pd.read_csv(datadir + 'Merged_Integrated_melt_rates.csv')\n",
    "Glaciers = df_names['Names']\n",
    "\n",
    "interesting_glaciers = ['Pine_Island', 'Thwaites', 'Crosson', 'Dotson', 'Getz_2', 'Venable', 'Getz', 'Getz_1' ]\n",
    "interesting_indices = np.where(np.isin(Glaciers, interesting_glaciers))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43 44 52 61 67 68 69 71]\n",
      "43         Getz_2\n",
      "44           Getz\n",
      "52         Getz_1\n",
      "61        Venable\n",
      "67    Pine_Island\n",
      "68       Thwaites\n",
      "69        Crosson\n",
      "71         Dotson\n",
      "Name: Names, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(interesting_indices)\n",
    "print(Glaciers[interesting_indices])\n",
    "len(Glaciers[interesting_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># 1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-8.413609</td>\n",
       "      <td>-5.942461</td>\n",
       "      <td>-6.794760</td>\n",
       "      <td>-4.981510</td>\n",
       "      <td>-6.548600</td>\n",
       "      <td>-6.890209</td>\n",
       "      <td>-7.231894</td>\n",
       "      <td>-4.604581</td>\n",
       "      <td>-7.584861</td>\n",
       "      <td>-4.915061</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.526445</td>\n",
       "      <td>-4.309380</td>\n",
       "      <td>-4.538844</td>\n",
       "      <td>-5.970263</td>\n",
       "      <td>-7.362037</td>\n",
       "      <td>-7.732249</td>\n",
       "      <td>-6.972290</td>\n",
       "      <td>-5.390824</td>\n",
       "      <td>-5.946024</td>\n",
       "      <td>-3.685726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-1.823234</td>\n",
       "      <td>-1.201954</td>\n",
       "      <td>-3.142510</td>\n",
       "      <td>-2.670408</td>\n",
       "      <td>-6.359390</td>\n",
       "      <td>-5.159474</td>\n",
       "      <td>-2.637508</td>\n",
       "      <td>-4.361383</td>\n",
       "      <td>-1.923420</td>\n",
       "      <td>-4.688521</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050775</td>\n",
       "      <td>-3.614895</td>\n",
       "      <td>-4.335759</td>\n",
       "      <td>-6.819175</td>\n",
       "      <td>-3.618371</td>\n",
       "      <td>-6.221341</td>\n",
       "      <td>-6.418642</td>\n",
       "      <td>-4.989903</td>\n",
       "      <td>-1.323176</td>\n",
       "      <td>-7.514523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-3.605442</td>\n",
       "      <td>-2.884086</td>\n",
       "      <td>-2.468552</td>\n",
       "      <td>-4.068516</td>\n",
       "      <td>-4.463484</td>\n",
       "      <td>-1.865358</td>\n",
       "      <td>-6.969004</td>\n",
       "      <td>-5.466586</td>\n",
       "      <td>-4.411549</td>\n",
       "      <td>-4.049332</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.059647</td>\n",
       "      <td>-4.980170</td>\n",
       "      <td>-4.262447</td>\n",
       "      <td>-0.610405</td>\n",
       "      <td>-3.866952</td>\n",
       "      <td>-2.053005</td>\n",
       "      <td>-2.829292</td>\n",
       "      <td>-1.272592</td>\n",
       "      <td>-4.511341</td>\n",
       "      <td>-1.349952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-21.449914</td>\n",
       "      <td>-20.570059</td>\n",
       "      <td>-19.899727</td>\n",
       "      <td>-23.212189</td>\n",
       "      <td>-20.787389</td>\n",
       "      <td>-19.075990</td>\n",
       "      <td>-22.901829</td>\n",
       "      <td>-18.525763</td>\n",
       "      <td>-20.380371</td>\n",
       "      <td>-21.462235</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.523703</td>\n",
       "      <td>-19.307042</td>\n",
       "      <td>-20.636665</td>\n",
       "      <td>-17.018780</td>\n",
       "      <td>-13.666499</td>\n",
       "      <td>-17.654303</td>\n",
       "      <td>-16.968275</td>\n",
       "      <td>-15.354581</td>\n",
       "      <td>-16.816891</td>\n",
       "      <td>-17.005557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-24.447653</td>\n",
       "      <td>-32.818858</td>\n",
       "      <td>-28.520485</td>\n",
       "      <td>-36.063666</td>\n",
       "      <td>-29.334189</td>\n",
       "      <td>-31.533917</td>\n",
       "      <td>-36.432817</td>\n",
       "      <td>-24.824092</td>\n",
       "      <td>-29.109719</td>\n",
       "      <td>-30.906729</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.560500</td>\n",
       "      <td>-32.235597</td>\n",
       "      <td>-29.586395</td>\n",
       "      <td>-22.604142</td>\n",
       "      <td>-2.746458</td>\n",
       "      <td>-2.770944</td>\n",
       "      <td>-4.112532</td>\n",
       "      <td>-1.635843</td>\n",
       "      <td>-1.486520</td>\n",
       "      <td>-2.152010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-15.067985</td>\n",
       "      <td>-21.842386</td>\n",
       "      <td>-16.456872</td>\n",
       "      <td>-23.358443</td>\n",
       "      <td>-19.444568</td>\n",
       "      <td>-16.617810</td>\n",
       "      <td>-21.323802</td>\n",
       "      <td>-18.283064</td>\n",
       "      <td>-19.254370</td>\n",
       "      <td>-20.444287</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.635928</td>\n",
       "      <td>-13.707167</td>\n",
       "      <td>-15.193405</td>\n",
       "      <td>-11.320781</td>\n",
       "      <td>-11.235661</td>\n",
       "      <td>-10.193431</td>\n",
       "      <td>-14.754618</td>\n",
       "      <td>-8.731806</td>\n",
       "      <td>-8.022121</td>\n",
       "      <td>-9.182577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-13.143792</td>\n",
       "      <td>-17.026532</td>\n",
       "      <td>-13.825222</td>\n",
       "      <td>-18.209323</td>\n",
       "      <td>-15.392142</td>\n",
       "      <td>-9.383227</td>\n",
       "      <td>-15.989702</td>\n",
       "      <td>-13.187187</td>\n",
       "      <td>-16.124847</td>\n",
       "      <td>-15.330571</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.842242</td>\n",
       "      <td>-14.658020</td>\n",
       "      <td>-12.541165</td>\n",
       "      <td>-11.534834</td>\n",
       "      <td>-11.247263</td>\n",
       "      <td>-10.096984</td>\n",
       "      <td>-12.121224</td>\n",
       "      <td>-9.265471</td>\n",
       "      <td>-8.149614</td>\n",
       "      <td>-7.859727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       # 1992       1993       1994       1995       1996       1997  \\\n",
       "43        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "44  -8.413609  -5.942461  -6.794760  -4.981510  -6.548600  -6.890209   \n",
       "52  -1.823234  -1.201954  -3.142510  -2.670408  -6.359390  -5.159474   \n",
       "61  -3.605442  -2.884086  -2.468552  -4.068516  -4.463484  -1.865358   \n",
       "67 -21.449914 -20.570059 -19.899727 -23.212189 -20.787389 -19.075990   \n",
       "68 -24.447653 -32.818858 -28.520485 -36.063666 -29.334189 -31.533917   \n",
       "69 -15.067985 -21.842386 -16.456872 -23.358443 -19.444568 -16.617810   \n",
       "71 -13.143792 -17.026532 -13.825222 -18.209323 -15.392142  -9.383227   \n",
       "\n",
       "         1998       1999       2000       2001  ...       2008       2009  \\\n",
       "43        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n",
       "44  -7.231894  -4.604581  -7.584861  -4.915061  ...  -7.526445  -4.309380   \n",
       "52  -2.637508  -4.361383  -1.923420  -4.688521  ...   1.050775  -3.614895   \n",
       "61  -6.969004  -5.466586  -4.411549  -4.049332  ...  -6.059647  -4.980170   \n",
       "67 -22.901829 -18.525763 -20.380371 -21.462235  ... -24.523703 -19.307042   \n",
       "68 -36.432817 -24.824092 -29.109719 -30.906729  ... -42.560500 -32.235597   \n",
       "69 -21.323802 -18.283064 -19.254370 -20.444287  ... -22.635928 -13.707167   \n",
       "71 -15.989702 -13.187187 -16.124847 -15.330571  ... -19.842242 -14.658020   \n",
       "\n",
       "         2010       2011       2012       2013       2014       2015  \\\n",
       "43        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "44  -4.538844  -5.970263  -7.362037  -7.732249  -6.972290  -5.390824   \n",
       "52  -4.335759  -6.819175  -3.618371  -6.221341  -6.418642  -4.989903   \n",
       "61  -4.262447  -0.610405  -3.866952  -2.053005  -2.829292  -1.272592   \n",
       "67 -20.636665 -17.018780 -13.666499 -17.654303 -16.968275 -15.354581   \n",
       "68 -29.586395 -22.604142  -2.746458  -2.770944  -4.112532  -1.635843   \n",
       "69 -15.193405 -11.320781 -11.235661 -10.193431 -14.754618  -8.731806   \n",
       "71 -12.541165 -11.534834 -11.247263 -10.096984 -12.121224  -9.265471   \n",
       "\n",
       "         2016       2017  \n",
       "43        NaN        NaN  \n",
       "44  -5.946024  -3.685726  \n",
       "52  -1.323176  -7.514523  \n",
       "61  -4.511341  -1.349952  \n",
       "67 -16.816891 -17.005557  \n",
       "68  -1.486520  -2.152010  \n",
       "69  -8.022121  -9.182577  \n",
       "71  -8.149614  -7.859727  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take the first raw of the dataframe melt_mean\n",
    "\n",
    "\n",
    "df_interesting_glaciers = melt_mean.iloc[interesting_indices]\n",
    "df_interesting_glaciers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate a linear regression of the melt rate for each glacier\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "Years = np.arange(1992, 2018, 1)\n",
    "\n",
    "lin_coeff = np.zeros((len(df_interesting_glaciers),2))\n",
    "lin_reg = np.zeros((len(df_interesting_glaciers),len(Years)))\n",
    "r_2 = np.zeros(len(df_interesting_glaciers))\n",
    "\n",
    "for glacier in range(0, len(df_interesting_glaciers)):\n",
    "    lin_coeff[glacier,:] = np.polyfit(Years, df_interesting_glaciers.iloc[glacier], 1)\n",
    "    lin_reg[glacier,:] = np.polyval(lin_coeff[glacier,:], Years)\n",
    "    r_2[glacier] = stats.linregress(Years, df_interesting_glaciers.iloc[glacier])[2]**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pdf file with the plots, one per page\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pp = PdfPages('Melt_rates.pdf')\n",
    "\n",
    "for glacier in range(0, len(df_interesting_glaciers)):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(Years, -df_interesting_glaciers.iloc[glacier], label='Melt rate')\n",
    "    plt.plot(Years, -lin_reg[glacier,:], label='Linear regression')\n",
    "    plt.title(Glaciers[interesting_indices[glacier]])\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('Melt rate [m/yr]')\n",
    "    plt.legend()\n",
    "    pp.savefig(fig)\n",
    "    plt.close()\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
